import asyncio
import base64
import io

import streamlit as st
from PIL import Image
from rsstvlm.agent.workflow import AgentWorkflow, StreamEvent
from rsstvlm.utils import deepseek_agent

st.set_page_config(
    page_title="å¤©ç©ºåœ°ä¸€ä½“åŒ–è¶…å…‰è°±é¥æ„Ÿåº”ç”¨å·¥ç¨‹å®éªŒå®¤",
    page_icon="ğŸ›°ï¸",
    layout="wide",
)


# ======================
# ğŸ¤– Agent åˆå§‹åŒ– (cached)
# ======================
@st.cache_resource
def get_agent():
    """Initialize agent once and cache it."""
    return asyncio.run(
        AgentWorkflow.create(deepseek_agent, timeout=1200, verbose=True)
    )


# ======================
# ğŸ§© ä¾§è¾¹æ åŠŸèƒ½
# ======================
with st.sidebar:
    st.header("ğŸ”§ æ§åˆ¶é¢æ¿")

    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå½“å‰å¯¹è¯"):
        st.session_state.messages = []
        st.rerun()

    st.divider()

    # åŠ è½½ Agent å¹¶æ˜¾ç¤ºå·¥å…·
    with st.spinner("æ­£åœ¨åŠ è½½ Agent..."):
        try:
            agent = get_agent()
            st.success("Agent å·²å°±ç»ª âœ…")
            st.markdown("#### ğŸ› ï¸ å¯ç”¨å·¥å…·")
            for tool in agent.tools:
                with st.expander(f"ğŸ“¦ {tool.metadata.name}"):
                    st.markdown(
                        f"**Description:** {tool.metadata.description}"
                    )
                    if tool.metadata.fn_schema:
                        st.markdown("**Args:**")
                        schema = tool.metadata.fn_schema.model_json_schema()
                        if "properties" in schema:
                            for param, info in schema["properties"].items():
                                param_type = info.get("type", "any")
                                param_desc = info.get("description", "")
                                st.markdown(
                                    f"- `{param}` ({param_type}): {param_desc}"
                                )
        except Exception as e:
            st.error(f"Agent åŠ è½½å¤±è´¥: {e}")

    st.divider()
    st.markdown("### ğŸ“Œ ä½¿ç”¨è¯´æ˜")
    st.markdown("""
    - ç›®å‰å·¥å…·è¾ƒå°‘ï¼Œé€æ¸å®Œå–„
    """)  # noqa: RUF001

# ======================
# ğŸ’¬ èŠå¤©å†å²åˆå§‹åŒ–
# ======================
if "messages" not in st.session_state:
    st.session_state.messages = []

# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        if isinstance(message["content"], list):
            # å¤šæ¨¡æ€æ¶ˆæ¯
            for part in message["content"]:
                if part["type"] == "text":
                    st.markdown(part["text"])
                elif part["type"] == "image_url":
                    st.image(part["image_url"]["url"], width=300)
        else:
            st.markdown(message["content"])

# ======================
# ğŸ–¼ï¸ å›¾åƒä¸Šä¼  + æ–‡æœ¬è¾“å…¥
# ======================
uploaded_file = st.file_uploader("ğŸ“ ä¸Šä¼ å›¾åƒ/è§†é¢‘")

# æ£€æŸ¥æ˜¯å¦å·²æœ‰å¤ªå¤šæ¶ˆæ¯(é˜²è¿‡è½½)
if len(st.session_state.messages) >= 10:
    st.warning("å¯¹è¯è¾ƒé•¿ï¼Œå»ºè®®ç‚¹å‡»ä¾§è¾¹æ ã€Œæ¸…ç©ºå½“å‰å¯¹è¯ã€ä»¥è·å¾—æœ€ä½³ä½“éªŒã€‚")  # noqa: RUF001

prompt = st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜")


# ======================
# ğŸ”„ Agent è°ƒç”¨å‡½æ•°
# ======================
def run_agent_with_placeholder(query: str, placeholder) -> tuple[str, list]:
    """Run agent with live streaming to a placeholder."""
    agent = get_agent()

    async def stream_to_placeholder():
        full_response = ""
        handler = agent.run(input=query)
        async for event in handler.stream_events():
            if isinstance(event, StreamEvent):
                full_response += event.delta
                placeholder.markdown(full_response + "â–Œ")
        result = await handler  # è·å–å®Œæ•´ç»“æœ

        # å¦‚æœæµå¼å“åº”ä¸ºç©º,ä»æœ€ç»ˆç»“æœä¸­è·å–å“åº”å†…å®¹
        if not full_response and result:
            response = result.get("response")
            if response and hasattr(response, "message"):
                full_response = str(response.message.content or "")

        sources = result.get("sources", []) if result else []
        return full_response, sources

    return asyncio.run(stream_to_placeholder())


# ======================
# ğŸ¤– å¤„ç†ç”¨æˆ·è¾“å…¥
# ======================
if prompt:
    # æ„å»ºç”¨æˆ·å†…å®¹
    user_content = [{"type": "text", "text": prompt}]

    # å¦‚æœä¸Šä¼ äº†å›¾ç‰‡
    if uploaded_file is not None:
        image = Image.open(uploaded_file).convert("RGB")
        buffered = io.BytesIO()
        image.save(buffered, format="JPEG")
        img_str = base64.b64encode(buffered.getvalue()).decode()
        image_url = f"data:image/jpeg;base64,{img_str}"
        user_content.insert(
            0, {"type": "image_url", "image_url": {"url": image_url}}
        )

    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    with st.chat_message("user"):
        if uploaded_file is not None:
            st.image(image, width=300)
        st.markdown(prompt)

    # æ·»åŠ åˆ°å†å²
    st.session_state.messages.append({"role": "user", "content": user_content})

    # ======================
    # ğŸ§  è°ƒç”¨ Agent
    # ======================
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        sources = []

        try:
            full_response, sources = run_agent_with_placeholder(
                prompt, message_placeholder
            )
            message_placeholder.markdown(full_response)

            # æ˜¾ç¤ºæ•°æ®æ¥æº
            if sources:
                with st.expander("ğŸ“š æ•°æ®æ¥æº", expanded=False):
                    for i, source in enumerate(sources, 1):
                        st.markdown(f"**{i}. {source.tool_name}**")
                        content = source.content
                        st.code(
                            content[:10000] + "..."
                            if len(content) > 10000
                            else content
                        )
        except Exception as e:
            error_msg = f"âŒ æ¨¡å‹è°ƒç”¨å¤±è´¥: {e!s}"
            message_placeholder.error(error_msg)
            full_response = error_msg

    # æ·»åŠ åŠ©æ‰‹å›å¤
    st.session_state.messages.append(
        {"role": "assistant", "content": full_response}
    )
